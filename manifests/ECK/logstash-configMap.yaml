apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  labels:
    application: elk
    component: logstash
data:
  pipelines.yml: |
    # Each input type is a seperate pipeline
    - pipeline.id: syslog-pipeline
      path.config: "/usr/share/logstash/config/input-syslog.yml"
      pipeline.workers: 3
      queue.type: persisted
    - pipeline.id: filebeat-pipeline
      path.config: "/usr/share/logstash/config/input-filebeat.yml"
    - pipeline.id: hec-pipeline
      path.config: "/usr/share/logstash/config/input-http.yml"
      pipeline.workers: 3
  input-syslog.yml: |
    # TCP and UDP Syslog inputs
    input {
      tcp {
        port => 8514
        type => syslog
        codec => plain { charset=>"ASCII" }
      }
      udp {
        port => 7514
        type => syslog
        codec => plain { charset=>"ASCII" }
      }
    }
    filter {
      if [type] == "syslog" {
        grok {
          match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
          add_field => [ "received_at", "%{@timestamp}" ]
          add_field => [ "received_from", "%{host}" ]
        }
        date {
          match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
        }
      }
    }
    output {
      stdout { codec => plain }
      elasticsearch {
        index => "logstash-syslog-%{+YYYY.MM.dd}"
        hosts => [ "${ES_HOSTS}" ]
        user => "${ES_USER}"
        password => "${ES_PASSWORD}"
        ssl_verification_mode => none
      }
    }
  input-filebeat.yml: |
    #filebeat input
    input {
      beats {
        port => 5044
      }
    }
    output {
      elasticsearch {
        index => "logstash-beats-%{+YYYY.MM.dd}"
        hosts => [ "${ES_HOSTS}" ]
        user => "${ES_USER}"
        password => "${ES_PASSWORD}"
        ssl_verification_mode => none
      }
    }
  input-http.yml: |
    # HTTP/S event collector
    input {
      http {
        id => "http"
        host => "0.0.0.0"
        port => "7080"
        type => hec
        ssl_enabled => false
      }
    }  
    #  http {
    #    id => "https"
    #    host => "0.0.0.0"
    #    port => "7443"
    #    type => hec
    #    ssl_enabled => true
    #    ssl_key => /usr/share/logstash/config/default.key
    #    ssl_certificate => /usr/share/logstash/config/default.crt
    #  }
    #}
    output {
      elasticsearch {
        index => "logstash-hec-%{+YYYY.MM.dd}"
        hosts => [ "${ES_HOSTS}" ]
        user => "${ES_USER}"
        password => "${ES_PASSWORD}"
        ssl_verification_mode => none
      }
    }
  default.key: |
    -----BEGIN PRIVATE KEY-----
    MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDsdcq5mZ/JzIwJ
    POVC6ooiI1mJwNGSsa7eTImBcg7J+1+QmkCyyGRG/hJTjYwjgL0swVYNSSTBi95v
    h+6rdSpJXfFUtzIm9/QfLQnbTn6zQaEtHNUMruzH2QLkn+OL0x5N/KAWr7tNnhPU
    YGRrURWvy6aKlz/mVOH8bxJRjQU3YARWXb/Aqvo01WL4D/XM34NfEVxogzqZrFa+
    sUWTncnFT6Z6Y88GEeg9Mxa/ABg+f0SFjXIcsH/sKC2bXTXqlj7p8XslfHU3MgNY
    rXdpGR4UFv3P8BDaEf8hfM0NXDhIDC2d31Txjk35HNRBKdn1WodOf9pgP7DExO2U
    jjiezvzxAgMBAAECggEAOyHV2YYubGOnnWPKHWrTsmfOq2E5x4qBpXvUYzentSEU
    q++3QD5WvV4qLRTXt8UpCbkrkNT6yR/2N0PyDpSVR5WjlUDe3NnjBazYqyw9CQzf
    ho2QRcS01+FQFOZbHAtmp7AGRMYbe/SNFu4oDqJPXw/5jOz4ANy3Ss5n8VbnuAni
    3Tn8cVp8DOzlhlP0D+ZSBJOWDxsaVrBNYC1rvikN7bFh3QnRKErnGmPZN4TIPyCl
    tlgDF+bCOl7/fSBAIoXAyzdnHxclyTZjhpTLxLZ2Mc2XNvXngN5Idg5l/R5JsEti
    TLbKexHeGgnDojJjXR26IflbzkBq0pfAu8DF2XDqxQKBgQD3J7f4iPAeq1myxs02
    eLH9zoseGJnSKLcgFND/Op8D8iRcCgfkIDcTem7P7MqpH6x/8tp0yfnSSwftZBe7
    VW10HYg9M2vfACf0O3VNvsLalWStFPmZy7yAcq7p5U746MPkRmGCrhTNH0QEGcoE
    kYTGtdmioada3mXTYtowpEQw2wKBgQD07BeTpmaAgvRo9e14bk3zXFvnE/VxuREE
    O+WuPo2mTqRmwHbwAQR37Nkuwp6n1sDSnaM8zhmhYZBQBYpoJ4HOlDzYEA0q+foh
    Z+kKcr2vyS1bC/Opa08V3aLKV+xmteE7BDf28SqKVXuwvfv68uI2oJ+hI+uHGny6
    kyZkonKdIwKBgQC8LFBkeJYhM6K6e6P4ahJSRDQlOOO8X2V1loO9Hvu8vFo0fSqe
    5Gwqd1fxFL8D3uquC8+JhdGf66JgeombBqKr+mQk/IaPpYXF7JMWGzwtwfqB0Ots
    zfJ59Vb5G65x0n56yZ8qKLILrldRq/TkX4qw4/mMWfmaNKNgOu4WhKqqawKBgD6w
    28wQULZeTr87C8DCwzMileeNBUtJqqBh0IWMP2etQ4mFhCwkpocn2eONL10YrBx8
    +xaKTqcvOOgyst28Fw7QhM5tNWGlwK+iUFU7T3BaV0Cxy3m3HPQk2hFe9gTIU1Fu
    4ABWdKQaA2IXDxOJ7fs7nAB8GEJptjlvhulFZ37vAoGAR1K2JtGUYLRiwMt1xNEP
    fgjBkTwZnCX1QY5nKpvJ6NpwJk5uOgybk7sT9eGv4TzNjsACxmH+Fn/AYGJ23sEc
    Twb8KvV6ohT9S/35Euv7gGt+bWnQCzvccIT53jbMUidhfgdVfLXANZS+OHS+yehd
    x31uf6fUJqFiLcWI5E4QaWA=
    -----END PRIVATE KEY-----
  default.crt: |
    -----BEGIN CERTIFICATE-----
    MIIDrjCCApagAwIBAgIEFdZqmjANBgkqhkiG9w0BAQsFADCBmDELMAkGA1UEBhMC
    VVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMRIwEAYDVQQKEwlNeUNv
    bXBhbnkxCzAJBgNVBAsTAklUMR4wHAYDVQQDExVsb2NhbGhvc3QubG9jYWxkb21h
    aW4xKTAnBgkqhkiG9w0BCQEWGnJvb3RAbG9jYWxob3N0LmxvY2FsZG9tYWluMB4X
    DTIxMDgxMTE4MjUzMFoXDTMxMDgwOTE4MjUzMFowgZgxCzAJBgNVBAYTAlVTMQsw
    CQYDVQQIEwJXQTEQMA4GA1UEBxMHU2VhdHRsZTESMBAGA1UEChMJTXlDb21wYW55
    MQswCQYDVQQLEwJJVDEeMBwGA1UEAxMVbG9jYWxob3N0LmxvY2FsZG9tYWluMSkw
    JwYJKoZIhvcNAQkBFhpyb290QGxvY2FsaG9zdC5sb2NhbGRvbWFpbjCCASIwDQYJ
    KoZIhvcNAQEBBQADggEPADCCAQoCggEBAOx1yrmZn8nMjAk85ULqiiIjWYnA0ZKx
    rt5MiYFyDsn7X5CaQLLIZEb+ElONjCOAvSzBVg1JJMGL3m+H7qt1Kkld8VS3Mib3
    9B8tCdtOfrNBoS0c1Qyu7MfZAuSf44vTHk38oBavu02eE9RgZGtRFa/LpoqXP+ZU
    4fxvElGNBTdgBFZdv8Cq+jTVYvgP9czfg18RXGiDOpmsVr6xRZOdycVPpnpjzwYR
    6D0zFr8AGD5/RIWNchywf+woLZtdNeqWPunxeyV8dTcyA1itd2kZHhQW/c/wENoR
    /yF8zQ1cOEgMLZ3fVPGOTfkc1EEp2fVah05/2mA/sMTE7ZSOOJ7O/PECAwEAATAN
    BgkqhkiG9w0BAQsFAAOCAQEAwgfjmNaZycH0uyuPVqUYjvHMULn4rSt9wh0kUGTb
    Wp4yIfNm4azg/hkHhhLd9qcOJECHPOyQ8GXbucQFjx1U1Zlw8npc5hEnq5rztg3K
    XS8pZiGRXenvnNK2YlH20aEsYda5QRRMcmSvmgDRh4RpugWATqIwObQP5qDIT+bc
    5NJDC1KybUX172H1q8Va/8cJnaDDn6NwR0eNXSTJ6VPLqrGy7bi7ByExCnbRaEkX
    e2+lv1i6xANtTylVMKaqHrFGEndysTWuSUb3Kun/QIpAmyQA0yBfJNgaE50roXmP
    tLG27U8hfviCUPaBOdELDUJ7R4NVWvF6PTY/03xYsO0vdQ==
    -----END CERTIFICATE-----
  logstash.yml: |
    # Settings file in YAML
    #
    # Settings can be specified either in hierarchical form, e.g.:
    #
    #   pipeline:
    #     batch:
    #       size: 125
    #       delay: 5
    #
    # Or as flat keys:
    #
    #   pipeline.batch.size: 125
    #   pipeline.batch.delay: 5
    #
    # ------------  Node identity ------------
    #
    # Use a descriptive name for the node:
    #
    # node.name: test
    #
    # If omitted the node name will default to the machine's host name
    #
    # ------------ Data path ------------------
    #
    # Which directory should be used by logstash and its plugins
    # for any persistent needs. Defaults to LOGSTASH_HOME/data
    #
    # path.data:
    #
    # ------------ Pipeline Settings --------------
    #
    # Set the number of workers that will, in parallel, execute the filters+outputs
    # stage of the pipeline.
    #
    # This defaults to the number of the host's CPU cores.
    #
    # pipeline.workers: 2
    #
    # How many workers should be used per output plugin instance
    #
    # pipeline.output.workers: 1
    #
    # How many events to retrieve from inputs before sending to filters+workers
    #
    # pipeline.batch.size: 125
    #
    # How long to wait before dispatching an undersized batch to filters+workers
    # Value is in milliseconds.
    #
    # pipeline.batch.delay: 5
    #
    # Force Logstash to exit during shutdown even if there are still inflight
    # events in memory. By default, logstash will refuse to quit until all
    # received events have been pushed to the outputs.
    #
    # WARNING: enabling this can lead to data loss during shutdown
    #
    # pipeline.unsafe_shutdown: false
    #
    # ------------ Pipeline Configuration Settings --------------
    #
    # Where to fetch the pipeline configuration for the main pipeline
    #
    # path.config:
    #
    # Pipeline configuration string for the main pipeline
    #
    # config.string:
    #
    # At startup, test if the configuration is valid and exit (dry run)
    #
    # config.test_and_exit: false
    #
    # Periodically check if the configuration has changed and reload the pipeline
    # This can also be triggered manually through the SIGHUP signal
    #
    # config.reload.automatic: false
    #
    # How often to check if the pipeline configuration has changed (in seconds)
    #
    # config.reload.interval: 3s
    #
    # Show fully compiled configuration as debug log message
    # NOTE: --log.level must be 'debug'
    #
    # config.debug: false
    #
    # When enabled, process escaped characters such as \n and \" in strings in the
    # pipeline configuration files.
    #
    # config.support_escapes: false
    #
    # ------------ Module Settings ---------------
    # Define modules here.  Modules definitions must be defined as an array.
    # The simple way to see this is to prepend each `name` with a `-`, and keep
    # all associated variables under the `name` they are associated with, and 
    # above the next, like this:
    #
    # modules:
    #   - name: MODULE_NAME
    #     var.PLUGINTYPE1.PLUGINNAME1.KEY1: VALUE
    #     var.PLUGINTYPE1.PLUGINNAME1.KEY2: VALUE
    #     var.PLUGINTYPE2.PLUGINNAME1.KEY1: VALUE
    #     var.PLUGINTYPE3.PLUGINNAME3.KEY1: VALUE
    #
    # Module variable names must be in the format of 
    #
    # var.PLUGIN_TYPE.PLUGIN_NAME.KEY
    #
    # modules:
    #
    # ------------ Cloud Settings ---------------
    # Define Elastic Cloud settings here.
    # Format of cloud.id is a base64 value e.g. dXMtZWFzdC0xLmF3cy5mb3VuZC5pbyRub3RhcmVhbCRpZGVudGlmaWVy
    # and it may have an label prefix e.g. staging:dXMtZ...
    # This will overwrite 'var.elasticsearch.hosts' and 'var.kibana.host'
    # cloud.id: <identifier>
    #
    # Format of cloud.auth is: <user>:<pass>
    # This is optional
    # If supplied this will overwrite 'var.elasticsearch.username' and 'var.elasticsearch.password'
    # If supplied this will overwrite 'var.kibana.username' and 'var.kibana.password'
    # cloud.auth: elastic:<password>
    #
    # ------------ Queuing Settings --------------
    #
    # Internal queuing model, "memory" for legacy in-memory based queuing and
    # "persisted" for disk-based acked queueing. Defaults is memory
    #
    # queue.type: memory
    #
    # If using queue.type: persisted, the directory path where the data files will be stored.
    # Default is path.data/queue
    #
    # path.queue:
    #
    # If using queue.type: persisted, the page data files size. The queue data consists of
    # append-only data files separated into pages. Default is 250mb
    #
    # queue.page_capacity: 250mb
    #
    # If using queue.type: persisted, the maximum number of unread events in the queue.
    # Default is 0 (unlimited)
    #
    # queue.max_events: 0
    #
    # If using queue.type: persisted, the total capacity of the queue in number of bytes.
    # If you would like more unacked events to be buffered in Logstash, you can increase the
    # capacity using this setting. Please make sure your disk drive has capacity greater than
    # the size specified here. If both max_bytes and max_events are specified, Logstash will pick
    # whichever criteria is reached first
    # Default is 1024mb or 1gb
    #
    # queue.max_bytes: 1024mb
    #
    # If using queue.type: persisted, the maximum number of acked events before forcing a checkpoint
    # Default is 1024, 0 for unlimited
    #
    # queue.checkpoint.acks: 1024
    #
    # If using queue.type: persisted, the maximum number of written events before forcing a checkpoint
    # Default is 1024, 0 for unlimited
    #
    # queue.checkpoint.writes: 1024
    #
    # If using queue.type: persisted, the interval in milliseconds when a checkpoint is forced on the head page
    # Default is 1000, 0 for no periodic checkpoint.
    #
    # queue.checkpoint.interval: 1000
    #
    # ------------ Dead-Letter Queue Settings --------------
    # Flag to turn on dead-letter queue.
    #
    # dead_letter_queue.enable: false

    # If using dead_letter_queue.enable: true, the maximum size of each dead letter queue. Entries
    # will be dropped if they would increase the size of the dead letter queue beyond this setting.
    # Default is 1024mb
    # dead_letter_queue.max_bytes: 1024mb

    # If using dead_letter_queue.enable: true, the directory path where the data files will be stored.
    # Default is path.data/dead_letter_queue
    #
    # path.dead_letter_queue:
    #
    # ------------ Metrics Settings --------------
    #
    # Bind address for the metrics REST endpoint
    #
    # http.host: "127.0.0.1"
    #
    # Bind port for the metrics REST endpoint, this option also accept a range
    # (9600-9700) and logstash will pick up the first available ports.
    #
    # http.port: 9600-9700
    #
    # ------------ Debugging Settings --------------
    #
    # Options for log.level:
    #   * fatal
    #   * error
    #   * warn
    #   * info (default)
    #   * debug
    #   * trace
    #
    # log.level: info
    # path.logs:
    #
    # ------------ Other Settings --------------
    #
    # Where to find custom plugins
    # path.plugins: []